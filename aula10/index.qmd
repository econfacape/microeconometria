---
title: "Aula 10 - Introdução à Econometria"
author: "João Ricardo F. de Lima"
date: "today"
editor: source
lang: pt
language: 
  toc-title-document: '<a href="https://www.facape.br/" target="_blank"><img src="https://github.com/econfacape/macroeconometria/blob/main/logofacape.jpg?raw=true" alt="Logotipo Facape" width="150"></a>'
format: 
  html:
    toc: true
    toc_float:
      collapsed: yes
      smooth_scroll: yes
    toc-location: left
    code-fold: false
    embed-resources: true
    page-layout: full
    fig-asp: 0.618
    fig-width: 10
    fig-height: 5
    fig-dpi: 100
    fig-align: center
    df-print: paged
    fontsize: 13pt
theme:
  light: flatly
execute:
  echo: TRUE
  message: false
  warning: false
---

# Quebra de Pressupostos do Modelo Clássico de Regressão Linear

# Autocorrelação e viés de especificação

<br>

## O que é Autocorrelação?

Pode existir autocorrelação no cross-section, mas é muito mais presente em séries temporais. Existe dependência entre os termos de erro $(E(u_i u_j \ne 0 \quad \forall \quad  i \ne j))$. Diversos fatores podem gerar a correlação serial, como por exemplo: 

a) inércia; 

b) viés de especificação; 

c) ausência de estacionariedade; 

Com relação à propriedade dos estimadores, com autocorrelação, os estimadores de MQO são não-viesados e consistentes, mas não são eficientes. **Os testes t e F não são mais válidos**. 

Nesta situação, da mesma forma que para a heterocedasticidade, é melhor utilizar o método de Mínimos Quadrados Generalizados (MQG).

Considere um modelo com resíduos que tem correlação de primeira ordem:

$$
u_t=\rho u_{t-1}+v_t
$$
em que $\rho$ é o parâmetro de autocorrelação e "v" é um termo de erro "bem comportado", ou seja, não autocorrelacionado que segue a distribuição Normal com média zero e variância constante $\sigma^2$. 

O coeficiente de autocorrelação $\rho$ pode ser obtido através de 

$$
\hat \rho = \frac {cov(\epsilon_t, \epsilon_{t-1})}{[var(\epsilon_t)^{1/2}] [var(\epsilon_{t-1})^{1/2}]}
$$

Com base nesta idéia, alguns testes foram desenvolvidos visando verificar a presença de autocorrelação nos resíduos da regressão. 

## Autocorrelação: Como Detectar?

Considere o modelo abaixo, uma série temporal que se inicia em 1947 e faz uma regressão do consumo em função da renda, da riqueza e da taxa de juros. As três primeiras variáveis estão em log. 

``` {r aula10_1, warning=FALSE, message=FALSE}
#Direcionado o R para o Diretorio a ser trabalhado
setwd('/Users/jricardofl/Dropbox/tempecon/facape')

#Inicio do Script

#Pacotes a serem usados
library(forecast)
library(ggplot2)
#library(easyGgplot2)
library(urca)
library(stargazer)
library(tseries)
library(lmtest)
library(car)
library(sandwich)
#install.packages('scatterplot3d')
library(scatterplot3d)

options(digits=4)

#Extracao dos dados
dados <- read.csv2('autocorrelacao.csv', header=T, sep=";", dec=".")
dados <- ts(dados, start=c(1947))

#Estimacao da Equacao de Regressao
regressao1 <- lm(log(consumo) ~log(renda) + log(riqueza) + tx_juros, data=dados)
summary(regressao1)
```

<br>

### MÉTODO GRÁFICO

<br>

Apesar de existirem testes estatísticos, uma análise gráfica pode ser útil para tentar verificar algum comportamento nos dados que de indicativo se existência de autocorrelação.


``` {r aula10_2, warning=FALSE, message=FALSE, fig_width= 12, fig_height= 16 }
#Analise dos residuos do modelo
par(mfrow=c(2,2))
plot(regressao1)
resid <- regressao1$residuals
resid <- ts(resid, start=c(1947))
```

``` {r eaula10_3, warning=FALSE, message=FALSE, fig_width= 12, fig_height= 10 }
par(mfrow=c(1,1))
scatterplot3d(lag(resid,-1), resid, pch=16, box=FALSE)
```

<br>

### TESTE DE DURBIN-WATSON

<br>

O teste mais conhecido é o "d" de Durbin-Watson (razão da soma das diferenças ao quadrado entre os sucessivos resíduos e a soma de quadrados dos resíduos):

$$
d=\frac{\sum_{t=2}^{t=n}(\hat{u}_t-\hat{u}_{t-1})^2}{\sum_{t=1}^{t=n}(\hat{u}_t^2)}
$$

Possui importantes premissas:

a) a regressão precisa ter intercepto; 

b) o termo de erro precisa ser um AR(1) ($u_t=\rho u_{t-1}+v_t$), não pode ser AR de ordem superior; 

c) o erro deve ser normal; 

d) o modelo não pode ter termos defasados da variável dependente (y); 

Não há um único valor crítico que leve a rejeição ou não da hipótese nula (ausência de autocorrelação), contudo o R mostra um valor de Probabilidade. Gujarati e Porter (2009) demonstram facilmente que $d\approx2(1- \hat{\rho})$. 

$$
\hat{u}_t=\hat{\rho} u_{t-1}+v_t
$$

Dado que $-1\le \rho \le 1$, tem-se que $0\le d \le 4$, que são os limites de "d". Como regra prática, espera-se que d esteja próximo de 2 para pressupor que não existe autocorrelação nos resíduos. Quanto mais próximo de 0 (zero), maior a evidência de auto positiva e de 4, de auto negativa.

``` {r aula10_4, warning=FALSE, message=FALSE}
#Teste de Durbin-Watson
# Testa the hipotese que nao existe correlacao de 1 lag nos residuos
dwtest(regressao1, alt="two.sided")
```

<br>

### TESTE DE BREUSCH-GODFREY

<br>

Teste que permite regressandos defasados inclusos como regressores, processos autoregressivos (AR) de ordens maiores do que 1 e 
Termos de médias móveis (MA). 

Suponha que o termo de erro siga a seguinte estrutura:

$$
u_t=\rho_1u_{t-1}+\rho_2u_{t-2}+\dots+\rho_pu_{t-p}+v_t
$$

$v_t$ é um erro que segue as hipóteses do MCRL.

A hipótese nula do teste BG é

$$
H_0=\rho_1=\rho_2=\dots=\rho_p=0
$$

**Ausência de autocorrelação de qualquer ordem**. Dada a não observação de $u_t$ é usado a sua estimativa e estimada uma regressão auxiliar de $e_t$ contra as variáveis explicativas e os termos de erros defasados. Em grandes amostras, o teste BG segue a distribuição $(n-p)R^2 \sim \chi_p^2$.

O teste BG possui as seguintes características: 

A) A variância de $u_t$ seja homocedástica;

B) Definir a ordem de "p". Normalmente isto é um processo de tentativa e erro, com o uso de critérios de Akaike ou Schwarz para definição do melhor modelo. Deve ser escolhido o modelo com menor valor de critério de informação;

<br>

```  {r aula10_5, warning=FALSE, message=FALSE}
#Teste de Breusch-Godfrey
#AIC(regressao1)
#BIC(regressao1)
bg1 <- bgtest(regressao1,1)
coeftest(bg1)
bg1

bg2 <- bgtest(regressao1,2)
coeftest(bg2)
bg2

bg3 <- bgtest(regressao1,3)
coeftest(bg3)
bg3
```

<br>

## Autocorrelação: Como Corrigir?

<br>

Existem diversas formas de corrigir a autocorrelação:

A) Transformar as séries, diferenciando-as, caso se saiba o valor de $\rho$ ou considerando $\rho=1$;

B) Fazer uma transformação generalizada: $Y_t- \hat{\rho}(Y_{t-1})$ para obter $\hat{\rho}$, fazer $\approx 1-\frac{d}{2}$;

C) Usar o método de correção dos erros padrões de Newey-West (HAC-Consistente com auto e hetero), desde que a amostra seja grande. Erros robustos.

Com base em Figueiro (2021), o cálculo dos erros-padrão por estimativas robustas serão desejáveis para formas mais gerais de correlação serial, diga-se, com autocorrelações de ordens superiores.

Desta forma, estima-se o modelo padrão de regressão linear por MQO. Em seguida, se pega os resíduos estimados de uma regressão auxiliar de $x_{1t}$ em função dos demais $x_{kt}$ e calcula-se $\hat a = \hat r_t \hat u_t$ em que $\hat u_t$ são os resíduos da estimação original por MQO. Por uma escolha de "g", que pode variar entre a parte inteira de $4(n/100)^{2/9}$ ou $n^{1/4}$, calcula-se

<br>

$$
\hat v= \sum_{t=1}^{n} k^2 \hat a^2_t + 2 \sum_{h=1}^{g} [1-h/(g+1)]\Big(\sum_{t=h+1}^{n} \hat a_t \hat a{t-h}\Big)
$$
<br>

e $ep(\hat \beta_1)=[SE/\hat \sigma]^2\sqrt(\hat v)$, em que SE é o erro padrão usual do MQO para $\hat \beta_j$.

Desta forma obtêm-se os erros-padrões robustos dos parâmetros. Fazendo uso do pacote `` sandwich``, e a opção para a matriz de variância-covariância consistente com heterocedasticidade e autocorrelação vcovHAC conforme o script abaixo. Conforme a ordem da autocorelação (se acima da primeira ordem), pode ser mais indicado considerar o tratamento para a estrutura geral de Newey e West (1987) e Wooldridge (1989), citados por Wooldridge
(2016, seção 12.5).

<br>

``` {r aula10_6, warning=FALSE, message=FALSE}
#Correcao do problema da Autocorrelacao - Duas formas

regressao1 <- lm(log(consumo) ~log(renda) + log(riqueza) + tx_juros, data=dados)
coeftest(regressao1, vcov=NeweyWest)
coeftest(regressao1, vcov=vcovHAC)
```

## Exemplo no Python

``` {python aula10_6a, warning=FALSE, message=FALSE}
#Direcionado o R para o Diretorio a ser trabalhado
import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf
import statsmodels.stats.stattools as sms
from statsmodels.tsa.stattools import adfuller
import statsmodels.stats.diagnostic as diag
from statsmodels.stats.diagnostic import acorr_breusch_godfrey

os.chdir('/Users/jricardofl/Dropbox/tempecon/facape')

#Inicio do Script

df = pd.read_csv(filepath_or_buffer = "autocorrelacao.csv", header=0, sep =';', decimal = ".")
df.head()

# Create a date range starting from 1947 with yearly frequency
date_range = pd.date_range(start='1947', periods=len(df), freq='YE')

# Set the date range as the index of the DataFrame
df.index = date_range

# Display the first few rows of the DataFrame to verify the index
print(df.head())

#Estimacao da Equacao de Regressao
reg1 = smf.ols('np.log(consumo) ~ np.log(renda) + np.log(riqueza) + tx_juros', data=df)

#Output do Resultado
result1 = reg1.fit()
print(result1.summary())

# Check for autocorrelation using the Durbin-Watson statistic
dw_statistic = sms.durbin_watson(result1.resid)
print('Durbin-Watson:', dw_statistic)

# Teste de Breusch-Godfrey
# Modelo deve estar estimado
aic_values = []
bic_values = []

max_lags = 10 

for lags in range(1, max_lags + 1):
    bg_test = acorr_breusch_godfrey(result1, nlags=lags)
    # Collect results
    aic_values.append(result1.aic)
    bic_values.append(result1.bic)

# Create DataFrame to analyze results
results = pd.DataFrame({
    'Lags': range(1, max_lags + 1),
    'AIC': aic_values,
    'BIC': bic_values
})

print(results)


# Roda o teste de Breusch-Godfrey com o lag definido
bg_test = acorr_breusch_godfrey(result1, nlags=1)  # Ajusta 'nlags'

print(f"Lagrange Multiplier Statistic: {bg_test[0]}")
print(f"P-Value: {bg_test[1]}")
print(f"F-Statistic: {bg_test[2]}")
print(f"P-Value (F-Statistic): {bg_test[3]}")


from statsmodels.stats.diagnostic import acorr_ljungbox

# Perform Ljung-Box test for autocorrelation
lb_test = acorr_ljungbox(result1.resid, lags=[1], return_df=True)
print('Ljung-Box Test:')
print(lb_test)
```

<hr>

# Viés de Especificação

<br>

**Omitir uma variável relevante** - *Conseqüências*: 

1) se a variável omitida for correlacionada com alguma incluída, os betas estimados são tendenciosos e inconsistentes; 

2) se não existir correlação, o intercepto é viesado; 

3) a variância do erro estará errada; 

4) IC, erros padrão e testes de hipóteses não são calculados corretamente.

**Inserir uma variável irrelevante** - *Conseqüências*: a perda da eficiência, ou seja, erros-padrão maiores do que as dos parâmetros do modelo verdadeiro. 

A conclusão é que incluir uma variável irrelevante é menos problemático do que omitir uma variável relevante. Existem alguns testes para identificar problemas na especificação dos modelos. 

<br>
	
## Viés de Especificação: como detectar?

<br>

O Teste Reset de Ramsey é usado para analisar má especificação do modelo. É um teste mais geral, tanto de variáveis irrelevantes, quanto de forma funcional incorreta e correlação entre os regressores e o termo de erro. A hipótese nula é de que o modelo inicialmente estimado está bem especificado. Uma falha no teste é que diz que o modelo não está bem especificado, mas não se sabe qual alternativa é a melhor. Deve-se testar outras formas, com outras variáveis e ir refazendo o teste.

Considere um modelo de regressão

$$
y=\beta_0+\beta_1x_1+ \dots +\beta_kx_k+u
$$

se a hipótese  $E(u|x_1,x_2, \dots ,x_k)=0$ for violada isto indica que a relação funcional entre as variáveis explicadas e explicativas está mal especificada, como mostra Wooldridge (2018, p. 90). 

O Teste Reset adiciona polinômios aos valores estimados por MQO na equação acima para verificar se são significativos e detectar tipos gerais de má especificação de formas funcionais.
	
Para fazer o teste é preciso definir quantas funções dos valores estimados serão incluídos na regressão expandida. No geral, quadráticos e cúbicos tem dado bons resultados.

A estatistica do teste é dada por

$$
F= \frac{\frac{R^2_{novo}-R^2_{velho}}{m}}{\frac{1-R^2_{novo}}{n-p}}
$$

em que m é o número de novos regressores e p é o número de parâmetros no novo modelo. 

$F \sim F_{m,n-p}$ com n igual ao número de observações.

<br>

## Viés de Especificação: exemplo no R.

``` {r aula10_7, warning=FALSE, message=FALSE}
#Direcionado o R para o Diretorio a ser trabalhado
#setwd('/Users/jricardofl/Dropbox/tempecon/facape/econometria2')

#Limpa o Ambiente Global
rm(list=ls())

#Inicio do Script
#Analise de Regressao com o R
#Pacotes a serem utilizados
library(foreign)
library(lmtest)
library(wooldridge)

data("wage2")
dados <- na.omit(wage2)

attach(dados)

#Regressao Multipla

regressao1 <- lm(lwage ~ educ + I(educ^2) + tenure)
summary(regressao1)

#Teste de especificação do Modelos
#Hipotese Nula: Modelo esta bem especificado.
resettest(regressao1, power=2 , type='fitted')
resettest(regressao1, power=3 , type='fitted')

#Estimacao do Modelo Linear
regressao2 <- lm(lwage ~ educ + exper + tenure)
summary(regressao2)

#Teste de especificacao do Modelos
#Hipotese Nula: Modelo esta bem especificado.
resettest(regressao2, power=2 , type='fitted')
resettest(regressao2, power=3 , type='fitted')
```
<br>

O teste Reset de Ramsey é usado para analisar má especificação do modelo. É um teste mais geral, tanto de variáveis irrelevantes, quanto de forma funcional incorreta e correlação entre os regressores e o termo de erro.

## Viés de Especificação: exemplo no Python.

``` {python aula10_7a, warning=FALSE, message=FALSE}
#Direcionado o R para o Diretorio a ser trabalhado
#setwd('/Users/jricardofl/Dropbox/tempecon/facape/econometria2')

import wooldridge
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.formula.api as smf
import scipy.stats as stats
from statsmodels.stats.diagnostic import linear_reset

#Carregar dados no computador
wage2 = wooldridge.data('wage2')

wage2 = wage2.dropna()

#Estimando a 1 Regressão Multipla Modelo Irrestrito
reg1 = smf.ols('np.log(wage) ~ educ + I(educ**2) + tenure', data=wage2)
#Output de Resultado
result1 = reg1.fit()
print(result1.summary())

# Ramsey's RESET test
reset_test = linear_reset(result1, power=2, use_f=True)
print("RESET test p-value:", reset_test.pvalue)

# Ramsey's RESET test
reset_test = linear_reset(result1, power=3, use_f=True)
print("RESET test p-value:", reset_test.pvalue)


#Estimando a 1 Regressão Multipla Modelo restrito
reg2 = smf.ols('np.log(wage) ~ educ + exper + tenure', data=wage2)
#Output de Resultado
result2 = reg2.fit()
print(result2.summary())

# Ramsey's RESET test
reset_test = linear_reset(result2, power=2, use_f=True)
print("RESET test p-value:", reset_test.pvalue)

# Ramsey's RESET test
reset_test = linear_reset(result2, power=3, use_f=True)
print("RESET test p-value:", reset_test.pvalue)

```
